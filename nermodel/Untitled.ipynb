{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from utils.data import Data\n",
    "from ner_model import build_model, evaluate\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_data(data):\n",
    "    ''' align a dictionnary of sequences \n",
    "        input:\n",
    "            data, dict of sequences { 'key1': ['I', 'dream', 'of', 'the', 'Moon'] \n",
    "                        'key2': [O, O, O, O, 'B-LOC']}\n",
    "        output:\n",
    "\n",
    "            dict of strings {'key1': ['I dream of the Moon'] \n",
    "                             'key2': ['O O     O  O   B-LOC']}\n",
    "    '''\n",
    "    spacings = [max([len(seq[i]) for seq in data.values()]) for i in range(len(data[list(data.keys())[0]]))]\n",
    "\n",
    "    data_aligned = dict()\n",
    "\n",
    "    for key, seq in data.items():\n",
    "        str_aligned = \"\"\n",
    "        for token, spacing in zip(seq, spacings):\n",
    "            str_aligned += token + \" \"*(spacing-len(token) + 1)\n",
    "        data_aligned[key] = str_aligned\n",
    "    return data_aligned\n",
    "#print(align_data(align)['inputs'])\n",
    "#print(align_data(align)['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER MODEL: decoding-style loading..\n",
      "Load Model weights from file ../pretrained/default_cnn.0.model\n",
      "building Network..\n",
      "use crf:  True\n",
      "use_char:  True\n",
      "char feature extractor:  CNN\n",
      "word feature extractor:  LSTM\n",
      "Build word sequence feature extractor: LSTM...\n",
      "Build word representation...\n",
      "Build char sequence feature extractor: CNN..\n",
      "build CRF...\n"
     ]
    }
   ],
   "source": [
    "path2xpt = '../pretrained/default_cnn.xpt'\n",
    "path2model = '../pretrained/default_cnn.0.model'\n",
    "decode_config_dict = {'load_model_dir':path2model # load model file\n",
    "                     }\n",
    "data = Data()\n",
    "#data.read_config(decode_config_dict)\n",
    "print(\"NER MODEL: decoding-style loading..\")\n",
    "## dset_dir must only contains dictionnary informations here (dset from the original model should be cleaned with the function clean_dset (to be coded))\n",
    "data.load_export(path2xpt)\n",
    "## supplementary configurations (optional, maybe not useful in deployment)\n",
    "data.read_config(decode_config_dict)\n",
    "## !!! we should be loading the weights here and not at each prediction!!!!\n",
    "data.HP_gpu = torch.cuda.is_available()\n",
    "#data.show_data_summary()\n",
    "model = build_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'working', 'at', 'the', 'APHP', '.', 'They', 'have', 'recently', 'refused', 'Google', 'and', 'Facebook', 'cooperation', '.', 'Camus', 'wrote', 'such', 'beautiful', 'plays']\n",
      "['I', 'am', 'working', 'at', 'the', 'APHP', '.', '', 'They', 'have', 'recently', 'refused', 'Google', 'and', 'Facebook', 'cooperation', '.', '', 'Camus', 'wrote', 'such', 'beautiful', 'plays', '']\n"
     ]
    }
   ],
   "source": [
    "input_data = 'I am working at the APHP. They have recently refused Google and Facebook cooperation. Camus wrote such beautiful plays'\n",
    "## Pre-processing from client \n",
    "sentences = nltk.sent_tokenize(input_data)\n",
    "input_client = []\n",
    "input_model = []\n",
    "for sent in sentences:\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    # we have to keep a sequence wo '' sentences separators for the client output\n",
    "    input_client += tokens\n",
    "    input_model += tokens + ['']\n",
    "print(input_client)\n",
    "print(input_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time 0.015 s\n",
      "Decoding speed: 206.9 st/s\n",
      "[['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O']]\n",
      "I am working at the APHP  . They have recently refused Google and   Facebook cooperation . Camus wrote such beautiful plays \n",
      "O O  O       O  O   B-LOC O O    O    O        O       B-ORG  I-ORG I-ORG    O           O B-PER O     O    O         O     \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#print(feed_data)\n",
    "### self.fix_alphabet() placed inside generate_instance* should prevent the vocabularies to grow indefinitely with fed inputs\n",
    "data.generate_instance_from_list(input_model)\n",
    "#print('***************')\n",
    "#print(data.raw_texts)\n",
    "#print(evaluate(data, model, 'raw', label_flag=False))\n",
    "#print('*****************')\n",
    "speed, acc, p, r, f, pred_results, pred_scores = evaluate(data, model, 'raw', label_flag=False) \n",
    "\n",
    "timed = time.time() - start_time\n",
    "print('Processing time {:.2} s'.format(timed))\n",
    "print('Decoding speed: {0:.1f} st/s'.format(speed))\n",
    "print(pred_results)\n",
    "# reconstruct a unique sequence for the client\n",
    "output_client = []\n",
    "for l in pred_results:\n",
    "    output_client += l\n",
    "\n",
    "output_aligned = align_data({'raw_input': input_client, 'labels':output_client})\n",
    "print(output_aligned['raw_input'])\n",
    "print(output_aligned['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed, acc, p, r, f, pred_results, pred_scores = evaluate(data, model, 'raw', label_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'working', 'at', 'the', 'APHP', 'in', 'France', '.', '', 'But', 'sometimes', 'unwillingly', 'for', 'Google', 'and', 'Facebook', 'too', '.', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O'],\n",
       " ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(feed_data)\n",
    "pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = [\"I\", \"love\", \"you\"]\n",
    "labels = ['B-Per', 'O', 'O']\n",
    "align = {'inputs':in_data, 'labels':labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
